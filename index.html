<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Camera Interaction App</title>
    <style>
      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }
      
      body {
        font-family: sans-serif;
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 16px;
        padding: 16px;
        background-color: #f0f0f0;
        min-height: 100vh;
      }
      
      h1 {
        font-size: 1.8rem;
        text-align: center;
        margin-bottom: 8px;
      }
      
      .controls,
      .io-areas {
        display: flex;
        gap: 10px;
        align-items: center;
        background-color: #fff;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        width: 100%;
        max-width: 600px;
      }
      
      .io-areas {
        flex-direction: column;
        align-items: stretch;
      }
      
      textarea {
        width: 100%;
        padding: 8px;
        border: 1px solid #ccc;
        border-radius: 4px;
        font-size: 14px;
        resize: vertical;
        min-height: 50px;
      }
      
      #videoContainer {
        position: relative;
        width: 100%;
        max-width: 480px;
        border: 2px solid #333;
        background-color: #000;
        border-radius: 8px;
        overflow: hidden;
        aspect-ratio: 4/3;
      }
      
      #videoFeed {
        display: block;
        width: 100%;
        height: 100%;
        border-radius: 6px;
        object-fit: cover;
      }
      
      #loadingOverlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        display: none;
        justify-content: center;
        align-items: center;
        background-color: rgba(0, 0, 0, 0.7);
        z-index: 10;
        border-radius: 6px;
        color: #ffffff;
        font-size: 1.5em;
        font-weight: bold;
      }
      
      button {
        padding: 12px 20px;
        font-size: 16px;
        cursor: pointer;
        border: none;
        border-radius: 4px;
        color: white;
        min-width: 100px;
      }
      
      #startButton.start {
        background-color: #28a745; /* Green */
      }
      
      #startButton.stop {
        background-color: #dc3545; /* Red */
      }
      
      .switch-camera {
        background-color: #007bff; /* Blue */
      }
      
      label {
        font-weight: bold;
        margin-bottom: 5px;
        display: block;
      }
      
      select {
        padding: 10px;
        border-radius: 4px;
        border: 1px solid #ccc;
        font-size: 14px;
      }
      
      .hidden {
        display: none;
      }
      
      /* Mobile-specific styling */
      @media (max-width: 600px) {
        body {
          padding: 12px;
          gap: 12px;
        }
        
        h1 {
          font-size: 1.5rem;
        }
        
        .controls {
          flex-direction: column;
          align-items: flex-start;
          gap: 12px;
        }
        
        .interval-wrapper {
          width: 100%;
          display: flex;
          flex-direction: column;
          gap: 5px;
        }
        
        select, button {
          width: 100%;
          padding: 12px;
          font-size: 16px; /* Larger touch targets */
        }
        
        #videoContainer {
          border-width: 1px;
        }
        
        textarea {
          font-size: 16px; /* Better readability on mobile */
        }
      }
    </style>
  </head>
  <body>
    <h1>Camera Interaction App</h1>

    <div id="videoContainer">
      <video id="videoFeed" autoplay playsinline></video>
      <div id="loadingOverlay">Loading...</div>
    </div>
    <canvas id="canvas" class="hidden"></canvas>
    <!-- For capturing frames -->

    <div class="io-areas">
      <div>
        <label for="instructionText">Instruction:</label>
        <textarea
          id="instructionText"
          name="Instruction"
        >What do you see?</textarea>
      </div>
      <div>
        <label for="responseText">Response:</label>
        <textarea
          id="responseText"
          name="Response"
          readonly
          placeholder="Server response will appear here..."
        ></textarea>
      </div>
    </div>

    <div class="controls">
      <div class="interval-wrapper">
        <label for="intervalSelect">Interval between requests:</label>
        <select id="intervalSelect" name="Interval between 2 requests">
          <option value="0" selected>0ms</option>
          <option value="100">100ms</option>
          <option value="250">250ms</option>
          <option value="500">500ms</option>
          <option value="1000">1s</option>
          <option value="2000">2s</option>
        </select>
      </div>
      <button id="startButton" class="start">Start</button>
    </div>

    <script type="module">
      import {
        AutoProcessor,
        AutoModelForVision2Seq,
        RawImage,
      } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers/dist/transformers.min.js";
      const video = document.getElementById("videoFeed");
      const canvas = document.getElementById("canvas");
      const instructionText = document.getElementById("instructionText");
      const responseText = document.getElementById("responseText");
      const intervalSelect = document.getElementById("intervalSelect");
      const startButton = document.getElementById("startButton");
      const loadingOverlay = document.getElementById("loadingOverlay");
      let stream = null;
      let isProcessing = false;
      let processor = null;
      let model = null;
      let facingMode = 'environment'; // Start with back camera
      let modelLoaded = false;
      
      async function initModel() {
        try {
          const modelId = "HuggingFaceTB/SmolVLM-500M-Instruct"; // or "HuggingFaceTB/SmolVLM-Instruct";
          loadingOverlay.style.display = "flex";
          responseText.value = "Loading processor...";
          
          processor = await AutoProcessor.from_pretrained(modelId).catch(error => {
            console.error("Failed to load processor:", error);
            responseText.value = "Failed to load processor. Try reloading the page.";
            loadingOverlay.style.display = "none";
            return null;
          });
          
          if (!processor) return;
          
          responseText.value = "Processor loaded. Loading model...";
          
          model = await AutoModelForVision2Seq.from_pretrained(modelId, {
            dtype: {
              embed_tokens: "fp16",
              vision_encoder: "q4",
              decoder_model_merged: "q4",
            },
            device: "webgpu",
          }).catch(error => {
            console.error("Failed to load model:", error);
            responseText.value = "Failed to load model. WebGPU may not be supported on your device.";
            loadingOverlay.style.display = "none";
            return null;
          });
          
          if (!model) return;
          
          modelLoaded = true;
          responseText.value = "Model loaded. Starting camera...";
          loadingOverlay.style.display = "none";
          
          // Start camera after model is loaded
          startCamera();
        } catch (err) {
          console.error("Error initializing model:", err);
          responseText.value = "Error initializing model: " + err.message;
          loadingOverlay.style.display = "none";
        }
      }
      
      async function startCamera() {
        // Stop any existing stream
        if (stream) {
          stream.getTracks().forEach(track => track.stop());
        }
        
        const constraints = {
          audio: false,
          video: { facingMode }
        };
        
        try {
          stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;
          responseText.value = `Camera ready (${facingMode === 'environment' ? 'back' : 'front'} camera)`;
        } catch (err) {
          console.error("Error accessing camera:", err);
          responseText.value = `Error accessing camera: ${err.message}`;
          alert(`Could not access camera: ${err.message}. Please check permissions.`);
        }
      }
      
      function stopCamera() {
        if (stream) {
          stream.getTracks().forEach(track => track.stop());
          stream = null;
          video.srcObject = null;
          responseText.value = "Camera stopped";
        }
      }
      
      function switchCamera() {
        facingMode = facingMode === 'environment' ? 'user' : 'environment';
        startCamera();
      }
      
      function captureImage() {
        if (!stream || !video.videoWidth) {
          console.warn("Video stream not ready for capture.");
          return null;
        }
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const context = canvas.getContext("2d", { willReadFrequently: true });
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const frame = context.getImageData(0, 0, canvas.width, canvas.height);
        return new RawImage(frame.data, frame.width, frame.height, 4);
      }
      
      async function runLocalVisionInference(imgElement, instruction) {
        if (!processor || !model) {
          throw new Error("Model not loaded yet");
        }
        
        try {
          const messages = [
            {
              role: "user",
              content: [{ type: "image" }, { type: "text", text: instruction }],
            },
          ];
          
          const text = processor.apply_chat_template(messages, {
            add_generation_prompt: true,
          });
          
          const inputs = await processor(text, [imgElement], {
            do_image_splitting: false,
          });
          
          const generatedIds = await model.generate({
            ...inputs,
            max_new_tokens: 100,
          });
          
          const output = processor.batch_decode(
            generatedIds.slice(null, [inputs.input_ids.dims.at(-1), null]),
            { skip_special_tokens: true }
          );
          
          return output[0].trim();
        } catch (error) {
          console.error("Inference error:", error);
          throw new Error("Failed to process image: " + error.message);
        }
      }
      
      async function sendData() {
        if (!isProcessing) return;
        
        if (!modelLoaded) {
          responseText.value = "Model not loaded yet. Please wait...";
          return;
        }
        
        const instruction = instructionText.value;
        const rawImg = captureImage();
        
        if (!rawImg) {
          responseText.value = "Camera capture failed";
          return;
        }
        
        try {
          responseText.value = "Processing image...";
          const reply = await runLocalVisionInference(rawImg, instruction);
          responseText.value = reply;
        } catch (e) {
          console.error(e);
          responseText.value = `Error: ${e.message}`;
          
          if (e.message.includes("not loaded")) {
            // Try to reinitialize model if needed
            if (!modelLoaded) {
              responseText.value = "Model failed to load. Please reload the page.";
              isProcessing = false;
              startButton.textContent = "Start";
              startButton.classList.replace("stop", "start");
            }
          }
        }
      }
      
      function sleep(ms) {
        return new Promise((resolve) => setTimeout(resolve, ms));
      }
      
      async function processingLoop() {
        const intervalMs = parseInt(intervalSelect.value, 10);
        while (isProcessing) {
          await sendData();
          if (!isProcessing) break;
          await sleep(intervalMs);
        }
      }
      
      function handleStart() {
        if (!modelLoaded) {
          responseText.value = "Model not loaded yet. Please wait...";
          return;
        }
        
        if (!stream) {
          responseText.value = "Camera not available. Starting camera...";
          startCamera();
          setTimeout(() => {
            if (stream) handleStart();
          }, 1000);
          return;
        }
        
        isProcessing = true;
        startButton.textContent = "Stop";
        startButton.classList.replace("start", "stop");
        instructionText.disabled = true;
        intervalSelect.disabled = true;
        responseText.value = "Processing started...";
        processingLoop();
      }
      
      function handleStop() {
        isProcessing = false;
        startButton.textContent = "Start";
        startButton.classList.replace("stop", "start");
        instructionText.disabled = false;
        intervalSelect.disabled = false;
        responseText.value = "Processing stopped";
      }
      
      startButton.addEventListener("click", () => {
        if (isProcessing) {
          handleStop();
        } else {
          handleStart();
        }
      });
      
      window.addEventListener("DOMContentLoaded", async () => {
        // Add camera switch button
        const controlsDiv = document.querySelector('.controls');
        const cameraSwitchBtn = document.createElement('button');
        cameraSwitchBtn.id = 'switchCameraBtn';
        cameraSwitchBtn.textContent = 'Switch Camera';
        cameraSwitchBtn.classList.add('switch-camera');
        
        cameraSwitchBtn.addEventListener('click', switchCamera);
        controlsDiv.appendChild(cameraSwitchBtn);
        
        // Check for WebGPU support
        if (!navigator.gpu) {
          const videoElement = document.getElementById("videoFeed");
          const warningElement = document.createElement("p");
          warningElement.textContent =
            "WebGPU is not available in this browser.";
          warningElement.style.color = "red";
          warningElement.style.textAlign = "center";
          warningElement.style.padding = "10px";
          warningElement.style.backgroundColor = "rgba(255,0,0,0.1)";
          warningElement.style.margin = "10px 0";
          warningElement.style.borderRadius = "4px";
          videoElement.parentNode.insertBefore(
            warningElement,
            videoElement.nextSibling
          );
          
          responseText.value = "WebGPU not supported in this browser. The model will not work.";
          return;
        }
        
        // Attempt to initialize model
        try {
          await initModel();
        } catch (err) {
          console.error("Failed to initialize:", err);
          responseText.value = "Failed to initialize application: " + err.message;
        }
      });
      
      window.addEventListener("beforeunload", () => {
        stopCamera();
      });
    </script>
  </body>
</html>
